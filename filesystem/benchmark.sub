# benchmark.sub - submit description file for FS benchmarking
#   we utilize condor_submit's ability to input variables on the command line
#   to make the single submit file operational for our four cases
#
# USAGE:
#   condor_submit [optional inputs] benchmark.sub
#
# INPUTS:
#   zfs           : Defined to anything if should use data files in /local/
#                   (default use data files in /hdfs/)
#   cp_to_scratch : Defined to anything if the file should be copied 
#                   to local scratch space before reading
#                   (default to read directly from remote mount)
#   max_branches  : Defined to maximum number of branches to read
#                   (default read all branches)
#   no_proc       : Defined to anything to skip processing of file
#                   (default to loop through all events in file)
#

# general definitions, same for all UMN submit scripts
universe     = vanilla
+CondorGroup = "cmsfarm"
nice_user    = yes
local        = /local/cms/user/eichl008
# prevent file system overloading, helps keep read-requests ordered
next_job_start_delay = 5

# requirements on runner
requirements = Machine != "zebra01.spa.umn.edu"    && \
               Machine != "zebra02.spa.umn.edu"    && \
               Machine != "zebra03.spa.umn.edu"    && \
               Machine != "zebra04.spa.umn.edu"    && \
               Machine != "scorpion1.spa.umn.edu"  && \
               Machine != "scorpion3.spa.umn.edu"  && \
               Machine != "scorpion5.spa.umn.edu"  && \
               Machine != "scorpion6.spa.umn.edu"  && \
               Machine != "scorpion7.spa.umn.edu"  && \
               Machine != "scorpion9.spa.umn.edu"  && \
               Machine != "scorpion10.spa.umn.edu" && \
               Machine != "scorpion11.spa.umn.edu" && \
               Machine != "scorpion12.spa.umn.edu" && \
               Machine != "scorpion13.spa.umn.edu" && \
               Machine != "scorpion14.spa.umn.edu" && \
               Machine != "scorpion15.spa.umn.edu" && \
               Machine != "scorpion17.spa.umn.edu" && \
               Machine != "scorpion18.spa.umn.edu" && \
               Machine != "scorpion21.spa.umn.edu" && \
               Machine != "scorpion22.spa.umn.edu" && \
               Machine != "scorpion23.spa.umn.edu" && \
               Machine != "scorpion24.spa.umn.edu" && \
               Machine != "scorpion48.spa.umn.edu"

# hold a job if it exits with a non-zero exit status
on_exit_hold = ExitCode != 0
on_exit_hold_subcode = ExitCode
on_exit_hold_reason  = "Script exited with non-zero exit code (code in HoldReasonSubCode)"

# executable we are running
executable = $(local)/umn-server/filesystem/run.sh
transfer_executable = no

script = $(local)/umn-server/filesystem/analysim.C

if defined max_branches
  mb = $(max_branches)
else
  mb = -1
endif

if defined cp_to_scratch
  cp = true
else
  cp = false
endif

if defined no_proc
  proc = false
else
  proc = true
endif

# command line arguments to executable
arguments  = "'$(script)(""$(datafile)"",""ggNtuplizer/EventTree"",$(cp),$(mb),$(proc))'"

# requires output directory to be already created
job_name = output/$(Cluster)-$(Process)
output = $(job_name).out
error  = $(job_name).out
if defined debug
  log    = $(job_name).log
endif
should_transfer_files   = yes
when_to_transfer_output = on_exit

if defined zfs
  dir=$(local)/bench_filesystem
else
  dir=/hdfs/cms/user/wadud/anTGC/ntuplesUL/ntuples2018UL/EGammaRun2018A12Nov2019UL2018v2/0000
endif

queue datafile matching files $(dir)/**.root
